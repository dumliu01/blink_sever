#!/usr/bin/env python3
# -*- coding: utf-8 -*-
"""
è‹¹æœç›¸å†Œ/Googleç›¸å†Œé£æ ¼çš„äººè„¸èšç±»ç³»ç»Ÿ
å®ç°é«˜è´¨é‡çš„äººè„¸æ£€æµ‹ã€ç‰¹å¾æå–å’Œæ™ºèƒ½èšç±»åŠŸèƒ½
"""

import cv2
import numpy as np
import insightface
from typing import List, Dict, Any, Tuple, Optional
import matplotlib.pyplot as plt
import matplotlib.patches as patches
from matplotlib.gridspec import GridSpec
import os
import json
import sqlite3
from datetime import datetime
import time
from pathlib import Path
import warnings
warnings.filterwarnings('ignore')

from sklearn.cluster import DBSCAN, KMeans, AgglomerativeClustering
from sklearn.metrics.pairwise import cosine_similarity
from sklearn.decomposition import PCA
from sklearn.preprocessing import StandardScaler
import seaborn as sns
import pandas as pd
from PIL import Image, ImageDraw, ImageFont
import io
import base64

# è®¾ç½®ä¸­æ–‡å­—ä½“
plt.rcParams['font.sans-serif'] = ['SimHei', 'Arial Unicode MS', 'DejaVu Sans']
plt.rcParams['axes.unicode_minus'] = False

class AppleStyleFaceClusterer:
    """è‹¹æœç›¸å†Œé£æ ¼çš„äººè„¸èšç±»å™¨"""
    
    def __init__(self, model_name: str = 'buffalo_l', db_path: str = 'apple_style_clustering.db'):
        """
        åˆå§‹åŒ–äººè„¸èšç±»å™¨
        
        Args:
            model_name: InsightFaceæ¨¡å‹åç§°
            db_path: æ•°æ®åº“è·¯å¾„
        """
        self.model_name = model_name
        self.db_path = db_path
        self.app = None
        self.face_detector = None
        self.face_recognizer = None
        
        # èšç±»å‚æ•°
        self.clustering_params = {
            'dbscan': {'eps': 0.35, 'min_samples': 2},
            'kmeans': {'n_clusters': 5},
            'hierarchical': {'n_clusters': 5, 'linkage': 'average'}
        }
        
        # è´¨é‡é˜ˆå€¼
        self.quality_thresholds = {
            'min_face_size': 30,  # æœ€å°äººè„¸å°ºå¯¸ (é™ä½ä»¥åŒ…å«æ›´å¤šäººè„¸)
            'min_confidence': 0.65,  # æœ€å°æ£€æµ‹ç½®ä¿¡åº¦ (é™ä½ä»¥åŒ…å«æ›´å¤šäººè„¸)
            'min_quality_score': 0.25  # æœ€å°è´¨é‡åˆ†æ•° (é™ä½ä»¥åŒ…å«æ›´å¤šäººè„¸)
        }
        
        self.load_model()
        self.init_database()
    
    def load_model(self):
        """åŠ è½½InsightFaceæ¨¡å‹"""
        try:
            print("ğŸ”„ æ­£åœ¨åŠ è½½InsightFaceæ¨¡å‹...")
            self.app = insightface.app.FaceAnalysis(name=self.model_name)
            self.app.prepare(ctx_id=0, det_size=(640, 640))
            print(f"âœ… InsightFaceæ¨¡å‹ {self.model_name} åŠ è½½æˆåŠŸ")
        except Exception as e:
            print(f"âŒ æ¨¡å‹åŠ è½½å¤±è´¥: {e}")
            raise e
    
    def init_database(self):
        """åˆå§‹åŒ–æ•°æ®åº“"""
        conn = sqlite3.connect(self.db_path)
        cursor = conn.cursor()
        
        # åˆ›å»ºäººè„¸ç‰¹å¾è¡¨
        cursor.execute('''
            CREATE TABLE IF NOT EXISTS face_embeddings (
                id INTEGER PRIMARY KEY AUTOINCREMENT,
                image_path TEXT NOT NULL,
                face_id INTEGER,
                embedding BLOB NOT NULL,
                bbox TEXT,
                landmarks TEXT,
                confidence REAL,
                quality_score REAL,
                cluster_id INTEGER,
                person_name TEXT,
                created_at TIMESTAMP DEFAULT CURRENT_TIMESTAMP,
                updated_at TIMESTAMP DEFAULT CURRENT_TIMESTAMP
            )
        ''')
        
        # åˆ›å»ºèšç±»å†å²è¡¨
        cursor.execute('''
            CREATE TABLE IF NOT EXISTS clustering_history (
                id INTEGER PRIMARY KEY AUTOINCREMENT,
                algorithm TEXT NOT NULL,
                parameters TEXT NOT NULL,
                total_faces INTEGER,
                total_clusters INTEGER,
                noise_faces INTEGER,
                created_at TIMESTAMP DEFAULT CURRENT_TIMESTAMP
            )
        ''')
        
        # åˆ›å»ºäººç‰©ä¿¡æ¯è¡¨
        cursor.execute('''
            CREATE TABLE IF NOT EXISTS person_info (
                cluster_id INTEGER PRIMARY KEY,
                person_name TEXT,
                representative_face_id INTEGER,
                face_count INTEGER,
                created_at TIMESTAMP DEFAULT CURRENT_TIMESTAMP,
                updated_at TIMESTAMP DEFAULT CURRENT_TIMESTAMP
            )
        ''')
        
        conn.commit()
        conn.close()
        print("âœ… æ•°æ®åº“åˆå§‹åŒ–å®Œæˆ")
    
    def add_images_from_directory(self, directory_path: str, recursive: bool = True) -> Dict[str, Any]:
        """
        ä»ç›®å½•æ·»åŠ å›¾åƒè¿›è¡Œäººè„¸èšç±»
        
        Args:
            directory_path: å›¾åƒç›®å½•è·¯å¾„
            recursive: æ˜¯å¦é€’å½’æœç´¢å­ç›®å½•
            
        Returns:
            æ·»åŠ ç»“æœç»Ÿè®¡
        """
        try:
            if not os.path.exists(directory_path):
                raise ValueError(f"ç›®å½•ä¸å­˜åœ¨: {directory_path}")
            
            # æ”¯æŒçš„å›¾åƒæ ¼å¼
            image_extensions = {'.jpg', '.jpeg', '.png', '.bmp', '.tiff', '.webp'}
            
            # æ”¶é›†å›¾åƒæ–‡ä»¶
            image_files = []
            if recursive:
                for root, dirs, files in os.walk(directory_path):
                    for file in files:
                        if Path(file).suffix.lower() in image_extensions:
                            image_files.append(os.path.join(root, file))
            else:
                for file in os.listdir(directory_path):
                    if Path(file).suffix.lower() in image_extensions:
                        image_files.append(os.path.join(directory_path, file))
            
            print(f"ğŸ“¸ å‘ç° {len(image_files)} ä¸ªå›¾åƒæ–‡ä»¶")
            
            # å¤„ç†å›¾åƒ
            results = {
                'total_images': len(image_files),
                'processed_images': 0,
                'total_faces': 0,
                'high_quality_faces': 0,
                'failed_images': 0,
                'errors': []
            }
            
            for i, img_path in enumerate(image_files):
                try:
                    print(f"ğŸ”„ å¤„ç†å›¾åƒ {i+1}/{len(image_files)}: {os.path.basename(img_path)}")
                    
                    faces = self._extract_faces_from_image(img_path)
                    results['total_faces'] += len(faces)
                    
                    high_quality_count = 0
                    for face in faces:
                        if self._is_high_quality_face(face):
                            self._save_face_embedding(img_path, face)
                            high_quality_count += 1
                    
                    results['high_quality_faces'] += high_quality_count
                    results['processed_images'] += 1
                    
                    if high_quality_count > 0:
                        print(f"  âœ… æ£€æµ‹åˆ° {len(faces)} ä¸ªäººè„¸ï¼Œ{high_quality_count} ä¸ªé«˜è´¨é‡")
                    else:
                        print(f"  âš ï¸  æ£€æµ‹åˆ° {len(faces)} ä¸ªäººè„¸ï¼Œä½†è´¨é‡ä¸è¶³")
                        
                except Exception as e:
                    results['failed_images'] += 1
                    results['errors'].append(f"{img_path}: {str(e)}")
                    print(f"  âŒ å¤„ç†å¤±è´¥: {e}")
            
            print(f"\nğŸ“Š å¤„ç†å®Œæˆ:")
            print(f"  æ€»å›¾åƒæ•°: {results['total_images']}")
            print(f"  æˆåŠŸå¤„ç†: {results['processed_images']}")
            print(f"  æ€»äººè„¸æ•°: {results['total_faces']}")
            print(f"  é«˜è´¨é‡äººè„¸: {results['high_quality_faces']}")
            print(f"  å¤±è´¥å›¾åƒ: {results['failed_images']}")
            
            return results
            
        except Exception as e:
            print(f"âŒ æ·»åŠ å›¾åƒå¤±è´¥: {e}")
            return {'error': str(e)}
    
    def _extract_faces_from_image(self, image_path: str) -> List[Dict[str, Any]]:
        """ä»å›¾åƒä¸­æå–äººè„¸"""
        try:
            img = cv2.imread(image_path)
            if img is None:
                return []
            
            # ä½¿ç”¨InsightFaceæ£€æµ‹äººè„¸
            faces = self.app.get(img)
            results = []
            
            for i, face in enumerate(faces):
                # è®¡ç®—äººè„¸è´¨é‡åˆ†æ•°
                quality_score = self._calculate_face_quality(img, face)
                
                # æå–å…³é”®ç‚¹
                landmarks = face.kps.tolist() if hasattr(face, 'kps') else []
                
                results.append({
                    'face_id': i,
                    'embedding': face.embedding,
                    'bbox': face.bbox.tolist(),
                    'landmarks': landmarks,
                    'confidence': float(face.det_score),
                    'quality_score': quality_score,
                    'age': getattr(face, 'age', None),
                    'gender': getattr(face, 'gender', None)
                })
            
            return results
            
        except Exception as e:
            print(f"æå–äººè„¸å¤±è´¥ {image_path}: {e}")
            return []
    
    def _calculate_face_quality(self, img: np.ndarray, face) -> float:
        """è®¡ç®—äººè„¸è´¨é‡åˆ†æ•°"""
        try:
            # åŸºç¡€è´¨é‡æŒ‡æ ‡
            bbox = face.bbox
            x1, y1, x2, y2 = map(int, bbox)
            
            # 1. äººè„¸å°ºå¯¸
            face_width = x2 - x1
            face_height = y2 - y1
            face_size_score = min(1.0, (face_width * face_height) / (100 * 100))
            
            # 2. æ£€æµ‹ç½®ä¿¡åº¦
            confidence_score = float(face.det_score)
            
            # 3. äººè„¸åŒºåŸŸæ¸…æ™°åº¦ï¼ˆä½¿ç”¨æ‹‰æ™®æ‹‰æ–¯ç®—å­ï¼‰
            face_roi = img[y1:y2, x1:x2]
            if face_roi.size > 0:
                gray_roi = cv2.cvtColor(face_roi, cv2.COLOR_BGR2GRAY)
                laplacian_var = cv2.Laplacian(gray_roi, cv2.CV_64F).var()
                sharpness_score = min(1.0, laplacian_var / 1000)
            else:
                sharpness_score = 0.0
            
            # 4. äººè„¸è§’åº¦ï¼ˆåŸºäºå…³é”®ç‚¹ï¼‰
            angle_score = 1.0
            if hasattr(face, 'kps') and len(face.kps) >= 5:
                # è®¡ç®—äººè„¸è§’åº¦
                left_eye = face.kps[0]
                right_eye = face.kps[1]
                nose = face.kps[2]
                
                # è®¡ç®—çœ¼ç›è¿çº¿è§’åº¦
                eye_angle = np.arctan2(right_eye[1] - left_eye[1], right_eye[0] - left_eye[0])
                angle_score = max(0.0, 1.0 - abs(eye_angle) / (np.pi / 4))
            
            # ç»¼åˆè´¨é‡åˆ†æ•°
            quality_score = (
                face_size_score * 0.3 +
                confidence_score * 0.4 +
                sharpness_score * 0.2 +
                angle_score * 0.1
            )
            
            return min(1.0, max(0.0, quality_score))
            
        except Exception as e:
            print(f"è®¡ç®—äººè„¸è´¨é‡å¤±è´¥: {e}")
            return 0.0
    
    def _is_high_quality_face(self, face: Dict[str, Any]) -> bool:
        """åˆ¤æ–­æ˜¯å¦ä¸ºé«˜è´¨é‡äººè„¸"""
        # æ£€æŸ¥äººè„¸å°ºå¯¸
        bbox = face['bbox']
        face_width = bbox[2] - bbox[0]
        face_height = bbox[3] - bbox[1]
        
        if (face_width < self.quality_thresholds['min_face_size'] or 
            face_height < self.quality_thresholds['min_face_size']):
            return False
        
        # æ£€æŸ¥æ£€æµ‹ç½®ä¿¡åº¦
        if face['confidence'] < self.quality_thresholds['min_confidence']:
            return False
        
        # æ£€æŸ¥è´¨é‡åˆ†æ•°
        if face['quality_score'] < self.quality_thresholds['min_quality_score']:
            return False
        
        return True
    
    def _save_face_embedding(self, image_path: str, face: Dict[str, Any]):
        """ä¿å­˜äººè„¸ç‰¹å¾åˆ°æ•°æ®åº“"""
        conn = sqlite3.connect(self.db_path)
        cursor = conn.cursor()
        
        cursor.execute('''
            INSERT INTO face_embeddings 
            (image_path, face_id, embedding, bbox, landmarks, confidence, quality_score)
            VALUES (?, ?, ?, ?, ?, ?, ?)
        ''', (
            image_path, 
            face['face_id'], 
            face['embedding'].tobytes(), 
            json.dumps(face['bbox']),
            json.dumps(face['landmarks']),
            face['confidence'],
            face['quality_score']
        ))
        
        conn.commit()
        conn.close()
    
    def load_all_embeddings(self) -> Tuple[List[int], np.ndarray, List[Dict[str, Any]]]:
        """åŠ è½½æ‰€æœ‰ç‰¹å¾å‘é‡"""
        conn = sqlite3.connect(self.db_path)
        cursor = conn.cursor()
        
        cursor.execute('''
            SELECT id, embedding, image_path, bbox, landmarks, confidence, quality_score, cluster_id
            FROM face_embeddings 
            ORDER BY id
        ''')
        
        ids = []
        embeddings = []
        metadata = []
        
        for row in cursor.fetchall():
            face_id, embedding_blob, image_path, bbox_json, landmarks_json, confidence, quality_score, cluster_id = row
            embedding = np.frombuffer(embedding_blob, dtype=np.float32)
            
            ids.append(face_id)
            embeddings.append(embedding)
            metadata.append({
                'id': face_id,
                'image_path': image_path,
                'bbox': json.loads(bbox_json),
                'landmarks': json.loads(landmarks_json),
                'confidence': float(confidence),
                'quality_score': float(quality_score),
                'cluster_id': cluster_id
            })
        
        conn.close()
        return ids, np.array(embeddings), metadata
    
    def cluster_faces(self, algorithm: str = 'dbscan', **kwargs) -> Dict[str, Any]:
        """
        æ‰§è¡Œäººè„¸èšç±»
        
        Args:
            algorithm: èšç±»ç®—æ³• ('dbscan', 'kmeans', 'hierarchical')
            **kwargs: ç®—æ³•ç‰¹å®šå‚æ•°
            
        Returns:
            èšç±»ç»“æœ
        """
        try:
            print(f"ğŸ”„ å¼€å§‹æ‰§è¡Œ {algorithm.upper()} èšç±»...")
            
            ids, embeddings, metadata = self.load_all_embeddings()
            
            if len(embeddings) == 0:
                return {'clusters': [], 'total_faces': 0, 'total_clusters': 0, 'error': 'æ²¡æœ‰å¯èšç±»çš„äººè„¸'}
            
            print(f"ğŸ“Š å¤„ç† {len(embeddings)} ä¸ªäººè„¸ç‰¹å¾")
            
            # æ ‡å‡†åŒ–ç‰¹å¾å‘é‡
            scaler = StandardScaler()
            embeddings_scaled = scaler.fit_transform(embeddings)
            
            # æ‰§è¡Œèšç±»
            if algorithm.lower() == 'dbscan':
                params = {**self.clustering_params['dbscan'], **kwargs}
                clustering = DBSCAN(eps=params['eps'], min_samples=params['min_samples'], metric='cosine')
                cluster_labels = clustering.fit_predict(embeddings_scaled)
                
            elif algorithm.lower() == 'kmeans':
                params = {**self.clustering_params['kmeans'], **kwargs}
                clustering = KMeans(n_clusters=params['n_clusters'], random_state=42, n_init=10)
                cluster_labels = clustering.fit_predict(embeddings_scaled)
                
            elif algorithm.lower() == 'hierarchical':
                params = {**self.clustering_params['hierarchical'], **kwargs}
                clustering = AgglomerativeClustering(
                    n_clusters=params['n_clusters'], 
                    metric='cosine', 
                    linkage=params['linkage']
                )
                cluster_labels = clustering.fit_predict(embeddings_scaled)
                
            else:
                raise ValueError(f"ä¸æ”¯æŒçš„èšç±»ç®—æ³•: {algorithm}")
            
            # ç»„ç»‡èšç±»ç»“æœ
            clusters = {}
            for i, label in enumerate(cluster_labels):
                if label not in clusters:
                    clusters[label] = []
                
                clusters[label].append({
                    'face_id': int(ids[i]),
                    'image_path': metadata[i]['image_path'],
                    'bbox': metadata[i]['bbox'],
                    'landmarks': metadata[i]['landmarks'],
                    'confidence': float(metadata[i]['confidence']),
                    'quality_score': float(metadata[i]['quality_score'])
                })
            
            # æ›´æ–°æ•°æ®åº“ä¸­çš„èšç±»æ ‡ç­¾
            self._update_cluster_labels(ids, cluster_labels)
            
            # ä¿å­˜èšç±»å†å²
            self._save_clustering_history(algorithm, params, len(embeddings), len(clusters), 
                                        len([x for x in cluster_labels if x == -1]))
            
            # è½¬æ¢æ ¼å¼
            cluster_list = []
            for cluster_id, faces in clusters.items():
                # é€‰æ‹©ä»£è¡¨æ€§äººè„¸ï¼ˆè´¨é‡æœ€é«˜çš„ï¼‰
                representative_face = max(faces, key=lambda x: x['quality_score'])
                
                cluster_list.append({
                    'cluster_id': int(cluster_id),
                    'faces': faces,
                    'face_count': len(faces),
                    'representative_face': representative_face,
                    'avg_quality': np.mean([f['quality_score'] for f in faces])
                })
            
            # æŒ‰äººè„¸æ•°é‡æ’åº
            cluster_list.sort(key=lambda x: x['face_count'], reverse=True)
            
            result = {
                'clusters': cluster_list,
                'total_faces': len(embeddings),
                'total_clusters': len(clusters),
                'noise_faces': len([x for x in cluster_labels if x == -1]),
                'algorithm': algorithm.upper(),
                'parameters': params,
                'success': True
            }
            
            print(f"âœ… èšç±»å®Œæˆ: {result['total_clusters']} ä¸ªèšç±», {result['noise_faces']} ä¸ªå™ªå£°ç‚¹")
            return result
            
        except Exception as e:
            print(f"âŒ èšç±»å¤±è´¥: {e}")
            return {'error': str(e), 'success': False}
    
    def _update_cluster_labels(self, face_ids: List[int], cluster_labels: List[int]):
        """æ›´æ–°æ•°æ®åº“ä¸­çš„èšç±»æ ‡ç­¾"""
        conn = sqlite3.connect(self.db_path)
        cursor = conn.cursor()
        
        for face_id, label in zip(face_ids, cluster_labels):
            cursor.execute('''
                UPDATE face_embeddings SET cluster_id = ?, updated_at = CURRENT_TIMESTAMP WHERE id = ?
            ''', (int(label), face_id))
        
        conn.commit()
        conn.close()
    
    def _save_clustering_history(self, algorithm: str, parameters: Dict, total_faces: int, 
                               total_clusters: int, noise_faces: int):
        """ä¿å­˜èšç±»å†å²"""
        conn = sqlite3.connect(self.db_path)
        cursor = conn.cursor()
        
        cursor.execute('''
            INSERT INTO clustering_history 
            (algorithm, parameters, total_faces, total_clusters, noise_faces)
            VALUES (?, ?, ?, ?, ?)
        ''', (algorithm, json.dumps(parameters), total_faces, total_clusters, noise_faces))
        
        conn.commit()
        conn.close()
    
    def visualize_clusters(self, save_path: str = None, max_faces_per_cluster: int = 9) -> None:
        """
        å¯è§†åŒ–èšç±»ç»“æœ
        
        Args:
            save_path: ä¿å­˜è·¯å¾„
            max_faces_per_cluster: æ¯ä¸ªèšç±»æœ€å¤šæ˜¾ç¤ºçš„äººè„¸æ•°
        """
        try:
            print("ğŸ¨ ç”Ÿæˆèšç±»å¯è§†åŒ–...")
            
            # è·å–èšç±»æ•°æ®
            conn = sqlite3.connect(self.db_path)
            cursor = conn.cursor()
            
            cursor.execute('''
                SELECT cluster_id, COUNT(*) as face_count
                FROM face_embeddings 
                WHERE cluster_id IS NOT NULL AND cluster_id != -1
                GROUP BY cluster_id 
                ORDER BY face_count DESC
            ''')
            cluster_stats = cursor.fetchall()
            
            if not cluster_stats:
                print("âŒ æ²¡æœ‰èšç±»æ•°æ®å¯è§†åŒ–")
                return
            
            # åˆ›å»ºå¯è§†åŒ–
            n_clusters = len(cluster_stats)
            cols = min(3, n_clusters)
            rows = (n_clusters + cols - 1) // cols
            
            fig = plt.figure(figsize=(cols * 6, rows * 6))
            fig.suptitle('è‹¹æœç›¸å†Œé£æ ¼äººè„¸èšç±»ç»“æœ', fontsize=16, fontweight='bold')
            
            for i, (cluster_id, face_count) in enumerate(cluster_stats):
                ax = plt.subplot(rows, cols, i + 1)
                
                # è·å–è¯¥èšç±»çš„äººè„¸
                cursor.execute('''
                    SELECT image_path, bbox, quality_score
                    FROM face_embeddings 
                    WHERE cluster_id = ?
                    ORDER BY quality_score DESC
                    LIMIT ?
                ''', (cluster_id, max_faces_per_cluster))
                
                faces = cursor.fetchall()
                
                if not faces:
                    continue
                
                # åˆ›å»ºäººè„¸ç½‘æ ¼
                face_size = 100
                grid_size = int(np.ceil(np.sqrt(len(faces))))
                cluster_img = np.ones((grid_size * face_size, grid_size * face_size, 3), dtype=np.uint8) * 255
                
                for j, (img_path, bbox_json, quality_score) in enumerate(faces):
                    if j >= max_faces_per_cluster:
                        break
                    
                    try:
                        # è¯»å–å›¾åƒ
                        img = cv2.imread(img_path)
                        if img is None:
                            continue
                        
                        # æå–äººè„¸åŒºåŸŸ
                        bbox = json.loads(bbox_json)
                        x1, y1, x2, y2 = map(int, bbox)
                        face_img = img[y1:y2, x1:x2]
                        
                        if face_img.size == 0:
                            continue
                        
                        # è°ƒæ•´å¤§å°
                        face_img = cv2.resize(face_img, (face_size, face_size))
                        
                        # æ”¾ç½®åˆ°ç½‘æ ¼ä¸­
                        row = j // grid_size
                        col = j % grid_size
                        y_start = row * face_size
                        y_end = (row + 1) * face_size
                        x_start = col * face_size
                        x_end = (col + 1) * face_size
                        
                        cluster_img[y_start:y_end, x_start:x_end] = face_img
                        
                    except Exception as e:
                        print(f"å¤„ç†äººè„¸å¤±è´¥ {img_path}: {e}")
                        continue
                
                # æ˜¾ç¤ºèšç±»
                ax.imshow(cv2.cvtColor(cluster_img, cv2.COLOR_BGR2RGB))
                ax.set_title(f'èšç±» {cluster_id}\n{face_count} ä¸ªäººè„¸', fontsize=12, fontweight='bold')
                ax.axis('off')
            
            conn.close()
            
            plt.tight_layout()
            
            if save_path:
                plt.savefig(save_path, dpi=300, bbox_inches='tight')
                print(f"âœ… èšç±»å¯è§†åŒ–å·²ä¿å­˜åˆ°: {save_path}")
            
            plt.show()
            
        except Exception as e:
            print(f"âŒ å¯è§†åŒ–å¤±è´¥: {e}")
    
    def get_cluster_statistics(self) -> Dict[str, Any]:
        """è·å–èšç±»ç»Ÿè®¡ä¿¡æ¯"""
        try:
            conn = sqlite3.connect(self.db_path)
            cursor = conn.cursor()
            
            # æ€»äººè„¸æ•°
            cursor.execute("SELECT COUNT(*) FROM face_embeddings")
            total_faces = cursor.fetchone()[0]
            
            # èšç±»ç»Ÿè®¡
            cursor.execute('''
                SELECT cluster_id, COUNT(*) as face_count, AVG(quality_score) as avg_quality
                FROM face_embeddings 
                WHERE cluster_id IS NOT NULL AND cluster_id != -1
                GROUP BY cluster_id 
                ORDER BY face_count DESC
            ''')
            cluster_stats = cursor.fetchall()
            
            # å™ªå£°ç‚¹æ•°é‡
            cursor.execute("SELECT COUNT(*) FROM face_embeddings WHERE cluster_id = -1")
            noise_count = cursor.fetchone()[0]
            
            # è´¨é‡ç»Ÿè®¡
            cursor.execute('''
                SELECT 
                    AVG(quality_score) as avg_quality,
                    MIN(quality_score) as min_quality,
                    MAX(quality_score) as max_quality,
                    AVG(confidence) as avg_confidence
                FROM face_embeddings
            ''')
            quality_stats = cursor.fetchone()
            
            conn.close()
            
            return {
                'total_faces': total_faces,
                'total_clusters': len(cluster_stats),
                'noise_faces': noise_count,
                'cluster_distribution': [
                    {
                        'cluster_id': cid, 
                        'face_count': count,
                        'avg_quality': float(avg_quality)
                    } 
                    for cid, count, avg_quality in cluster_stats
                ],
                'quality_stats': {
                    'avg_quality': float(quality_stats[0]) if quality_stats[0] else 0,
                    'min_quality': float(quality_stats[1]) if quality_stats[1] else 0,
                    'max_quality': float(quality_stats[2]) if quality_stats[2] else 0,
                    'avg_confidence': float(quality_stats[3]) if quality_stats[3] else 0
                }
            }
            
        except Exception as e:
            print(f"âŒ è·å–ç»Ÿè®¡ä¿¡æ¯å¤±è´¥: {e}")
            return {}
    
    def find_similar_faces(self, image_path: str, threshold: float = 0.6, max_results: int = 10) -> List[Dict[str, Any]]:
        """
        æŸ¥æ‰¾ç›¸ä¼¼äººè„¸
        
        Args:
            image_path: æŸ¥è¯¢å›¾åƒè·¯å¾„
            threshold: ç›¸ä¼¼åº¦é˜ˆå€¼
            max_results: æœ€å¤§ç»“æœæ•°
            
        Returns:
            ç›¸ä¼¼äººè„¸åˆ—è¡¨
        """
        try:
            # æå–æŸ¥è¯¢å›¾åƒçš„äººè„¸ç‰¹å¾
            faces = self._extract_faces_from_image(image_path)
            if not faces:
                return []
            
            query_face = max(faces, key=lambda x: x['quality_score'])
            query_embedding = query_face['embedding']
            
            # åŠ è½½æ‰€æœ‰ç‰¹å¾å‘é‡
            ids, embeddings, metadata = self.load_all_embeddings()
            
            if len(embeddings) == 0:
                return []
            
            # è®¡ç®—ç›¸ä¼¼åº¦
            similarities = cosine_similarity([query_embedding], embeddings)[0]
            
            # æ‰¾åˆ°ç›¸ä¼¼çš„äººè„¸
            similar_faces = []
            for i, similarity in enumerate(similarities):
                if similarity >= threshold:
                    similar_faces.append({
                        'face_id': int(ids[i]),
                        'image_path': metadata[i]['image_path'],
                        'bbox': metadata[i]['bbox'],
                        'confidence': float(metadata[i]['confidence']),
                        'quality_score': float(metadata[i]['quality_score']),
                        'similarity': float(similarity),
                        'cluster_id': metadata[i]['cluster_id']
                    })
            
            # æŒ‰ç›¸ä¼¼åº¦æ’åºå¹¶é™åˆ¶ç»“æœæ•°
            similar_faces.sort(key=lambda x: x['similarity'], reverse=True)
            return similar_faces[:max_results]
            
        except Exception as e:
            print(f"âŒ æŸ¥æ‰¾ç›¸ä¼¼äººè„¸å¤±è´¥: {e}")
            return []
    
    def export_clusters_to_json(self, output_path: str) -> bool:
        """å¯¼å‡ºèšç±»ç»“æœåˆ°JSONæ–‡ä»¶"""
        try:
            stats = self.get_cluster_statistics()
            
            # è·å–è¯¦ç»†çš„èšç±»æ•°æ®
            conn = sqlite3.connect(self.db_path)
            cursor = conn.cursor()
            
            cursor.execute('''
                SELECT cluster_id, image_path, bbox, confidence, quality_score, created_at
                FROM face_embeddings 
                WHERE cluster_id IS NOT NULL AND cluster_id != -1
                ORDER BY cluster_id, quality_score DESC
            ''')
            
            clusters_data = {}
            for row in cursor.fetchall():
                cluster_id, image_path, bbox_json, confidence, quality_score, created_at = row
                
                if cluster_id not in clusters_data:
                    clusters_data[cluster_id] = {
                        'cluster_id': cluster_id,
                        'faces': []
                    }
                
                clusters_data[cluster_id]['faces'].append({
                    'image_path': image_path,
                    'bbox': json.loads(bbox_json),
                    'confidence': float(confidence),
                    'quality_score': float(quality_score),
                    'created_at': created_at
                })
            
            conn.close()
            
            # ç»„ç»‡å¯¼å‡ºæ•°æ®
            export_data = {
                'export_info': {
                    'export_time': datetime.now().isoformat(),
                    'total_faces': stats['total_faces'],
                    'total_clusters': stats['total_clusters'],
                    'noise_faces': stats['noise_faces']
                },
                'statistics': stats,
                'clusters': list(clusters_data.values())
            }
            
            # ä¿å­˜åˆ°æ–‡ä»¶
            with open(output_path, 'w', encoding='utf-8') as f:
                json.dump(export_data, f, ensure_ascii=False, indent=2)
            
            print(f"âœ… èšç±»ç»“æœå·²å¯¼å‡ºåˆ°: {output_path}")
            return True
            
        except Exception as e:
            print(f"âŒ å¯¼å‡ºå¤±è´¥: {e}")
            return False


def demo_apple_style_clustering():
    """è‹¹æœç›¸å†Œé£æ ¼äººè„¸èšç±»æ¼”ç¤º"""
    print("ğŸ è‹¹æœç›¸å†Œé£æ ¼äººè„¸èšç±»æ¼”ç¤º")
    print("=" * 50)
    
    # åˆ›å»ºèšç±»å™¨
    clusterer = AppleStyleFaceClusterer()
    
    # æµ‹è¯•å›¾åƒç›®å½•
    test_dir = "../test_images"
    
    if os.path.exists(test_dir):
        print(f"\nğŸ“ ä»ç›®å½• {test_dir} æ·»åŠ å›¾åƒ...")
        results = clusterer.add_images_from_directory(test_dir, recursive=False)
        
        if results.get('high_quality_faces', 0) > 0:
            print(f"\nğŸ” æ‰§è¡ŒDBSCANèšç±»...")
            dbscan_result = clusterer.cluster_faces('dbscan', eps=0.35, min_samples=2)
            
            if dbscan_result.get('success'):
                print(f"\nğŸ“Š èšç±»ç»Ÿè®¡ä¿¡æ¯:")
                stats = clusterer.get_cluster_statistics()
                print(f"  æ€»äººè„¸æ•°: {stats['total_faces']}")
                print(f"  èšç±»æ•°: {stats['total_clusters']}")
                print(f"  å™ªå£°ç‚¹: {stats['noise_faces']}")
                print(f"  å¹³å‡è´¨é‡: {stats['quality_stats']['avg_quality']:.3f}")
                
                print(f"\nğŸ“ˆ èšç±»åˆ†å¸ƒ:")
                for cluster in stats['cluster_distribution']:
                    print(f"  èšç±» {cluster['cluster_id']}: {cluster['face_count']} ä¸ªäººè„¸ (è´¨é‡: {cluster['avg_quality']:.3f})")
                
                print(f"\nğŸ¨ ç”Ÿæˆå¯è§†åŒ–...")
                os.makedirs("output", exist_ok=True)
                clusterer.visualize_clusters("output/apple_style_clusters.png")
                
                print(f"\nğŸ’¾ å¯¼å‡ºç»“æœ...")
                clusterer.export_clusters_to_json("output/clusters_export.json")
                
            else:
                print(f"âŒ èšç±»å¤±è´¥: {dbscan_result.get('error', 'æœªçŸ¥é”™è¯¯')}")
        else:
            print("âŒ æ²¡æœ‰æ£€æµ‹åˆ°é«˜è´¨é‡äººè„¸")
    else:
        print(f"âŒ æµ‹è¯•ç›®å½• {test_dir} ä¸å­˜åœ¨ï¼Œè¯·æ·»åŠ æµ‹è¯•å›¾åƒ")


if __name__ == "__main__":
    demo_apple_style_clustering()
