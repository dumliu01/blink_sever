#!/usr/bin/env python3
"""
é‡åŒ–è¯Šæ–­è„šæœ¬ - åˆ†æé‡åŒ–åæ€§èƒ½é—®é¢˜
"""

import os
import sys
import time
import numpy as np
import onnxruntime as ort
import onnx
from pathlib import Path

def analyze_model_structure(model_path: str):
    """åˆ†ææ¨¡å‹ç»“æ„"""
    print(f"åˆ†ææ¨¡å‹ç»“æ„: {model_path}")
    
    try:
        # åŠ è½½ ONNX æ¨¡å‹
        model = onnx.load(model_path)
        
        print(f"  æ¨¡å‹ç‰ˆæœ¬: {model.opset_import[0].version}")
        print(f"  èŠ‚ç‚¹æ•°é‡: {len(model.graph.node)}")
        
        # ç»Ÿè®¡æ“ä½œç±»å‹
        op_types = {}
        for node in model.graph.node:
            op_type = node.op_type
            op_types[op_type] = op_types.get(op_type, 0) + 1
        
        print("  æ“ä½œç±»å‹ç»Ÿè®¡:")
        for op_type, count in sorted(op_types.items()):
            print(f"    {op_type}: {count}")
        
        # æ£€æŸ¥é‡åŒ–ç›¸å…³æ“ä½œ
        quant_ops = ['QuantizeLinear', 'DequantizeLinear', 'QLinearConv', 'QLinearMatMul']
        quant_count = sum(op_types.get(op, 0) for op in quant_ops)
        print(f"  é‡åŒ–æ“ä½œæ•°é‡: {quant_count}")
        
        # æ£€æŸ¥è¾“å…¥è¾“å‡º
        print("  è¾“å…¥:")
        for input_info in model.graph.input:
            print(f"    {input_info.name}: {[d.dim_value for d in input_info.type.tensor_type.shape.dim]}")
        
        print("  è¾“å‡º:")
        for output_info in model.graph.output:
            print(f"    {output_info.name}: {[d.dim_value for d in output_info.type.tensor_type.shape.dim]}")
            
    except Exception as e:
        print(f"  é”™è¯¯: {e}")

def test_different_providers(model_path: str, input_shape: tuple = (1, 3, 640, 640)):
    """æµ‹è¯•ä¸åŒæ‰§è¡Œæä¾›è€…çš„æ€§èƒ½"""
    print(f"\næµ‹è¯•ä¸åŒæ‰§è¡Œæä¾›è€…: {model_path}")
    
    # å‡†å¤‡æµ‹è¯•æ•°æ®
    dummy_input = np.random.randn(*input_shape).astype(np.float32)
    
    # æµ‹è¯•é…ç½®
    test_configs = [
        {
            'name': 'é»˜è®¤ CPU',
            'providers': ['CPUExecutionProvider'],
            'options': [{}]
        },
        {
            'name': 'ä¼˜åŒ– CPU',
            'providers': ['CPUExecutionProvider'],
            'options': [{
                'CPUExecutionProvider': {
                    'enable_cpu_mem_arena': True,
                    'arena_extend_strategy': 'kSameAsRequested',
                    'enable_mem_pattern': True,
                    'enable_mem_reuse': True,
                }
            }]
        },
        {
            'name': 'CPU + çº¿ç¨‹ä¼˜åŒ–',
            'providers': ['CPUExecutionProvider'],
            'options': [{
                'CPUExecutionProvider': {
                    'enable_cpu_mem_arena': True,
                    'arena_extend_strategy': 'kSameAsRequested',
                    'enable_mem_pattern': True,
                    'enable_mem_reuse': True,
                    'intra_op_num_threads': 4,
                    'inter_op_num_threads': 4,
                }
            }]
        }
    ]
    
    results = {}
    
    for config in test_configs:
        try:
            print(f"  æµ‹è¯• {config['name']}...")
            
            # åˆ›å»ºä¼šè¯
            session = ort.InferenceSession(
                model_path,
                providers=config['providers'],
                provider_options=config['options']
            )
            
            # è·å–è¾“å…¥åç§°
            input_name = session.get_inputs()[0].name
            
            # é¢„çƒ­
            for _ in range(5):
                session.run(None, {input_name: dummy_input})
            
            # æ€§èƒ½æµ‹è¯•
            times = []
            for _ in range(20):
                start_time = time.time()
                session.run(None, {input_name: dummy_input})
                end_time = time.time()
                times.append(end_time - start_time)
            
            avg_time = np.mean(times)
            fps = 1.0 / avg_time
            
            results[config['name']] = {
                'avg_time': avg_time,
                'fps': fps,
                'providers': session.get_providers()
            }
            
            print(f"    å¹³å‡æ—¶é—´: {avg_time:.4f}s, FPS: {fps:.2f}")
            
        except Exception as e:
            print(f"    é”™è¯¯: {e}")
    
    return results

def compare_models():
    """å¯¹æ¯”æ¨¡å‹æ€§èƒ½"""
    fp32_model = "models/onnx/buffalo_l_fp32.onnx"
    int8_model = "models/onnx/buffalo_l_fp32_dynamic_int8.onnx"
    
    if not os.path.exists(fp32_model) or not os.path.exists(int8_model):
        print("æ¨¡å‹æ–‡ä»¶ä¸å­˜åœ¨ï¼Œè¯·å…ˆè¿è¡Œé‡åŒ–è„šæœ¬")
        return
    
    print("=== é‡åŒ–è¯Šæ–­æŠ¥å‘Š ===\n")
    
    # 1. åˆ†ææ¨¡å‹ç»“æ„
    print("1. æ¨¡å‹ç»“æ„åˆ†æ")
    print("FP32 æ¨¡å‹:")
    analyze_model_structure(fp32_model)
    
    print("\nINT8 é‡åŒ–æ¨¡å‹:")
    analyze_model_structure(int8_model)
    
    # 2. æµ‹è¯•ä¸åŒæ‰§è¡Œæä¾›è€…
    print("\n2. æ‰§è¡Œæä¾›è€…æ€§èƒ½æµ‹è¯•")
    print("FP32 æ¨¡å‹:")
    fp32_results = test_different_providers(fp32_model)
    
    print("\nINT8 æ¨¡å‹:")
    int8_results = test_different_providers(int8_model)
    
    # 3. æ€§èƒ½å¯¹æ¯”
    print("\n3. æ€§èƒ½å¯¹æ¯”æ€»ç»“")
    if 'ä¼˜åŒ– CPU' in fp32_results and 'ä¼˜åŒ– CPU' in int8_results:
        fp32_fps = fp32_results['ä¼˜åŒ– CPU']['fps']
        int8_fps = int8_results['ä¼˜åŒ– CPU']['fps']
        
        print(f"FP32 æ¨¡å‹ (ä¼˜åŒ– CPU): {fp32_fps:.2f} FPS")
        print(f"INT8 æ¨¡å‹ (ä¼˜åŒ– CPU): {int8_fps:.2f} FPS")
        print(f"åŠ é€Ÿæ¯”: {int8_fps/fp32_fps:.2f}x")
        
        if int8_fps < fp32_fps:
            print("\nâŒ é‡åŒ–æ¨¡å‹æ€§èƒ½ä¸‹é™çš„å¯èƒ½åŸå› :")
            print("  1. é‡åŒ–å‚æ•°ä¸å½“ï¼Œå¯¼è‡´é¢å¤–è®¡ç®—å¼€é”€")
            print("  2. æ¨¡å‹ç»“æ„ä¸é€‚åˆåŠ¨æ€é‡åŒ–")
            print("  3. æ‰§è¡Œæä¾›è€…é…ç½®éœ€è¦è¿›ä¸€æ­¥ä¼˜åŒ–")
            print("  4. æŸäº›å…³é”®å±‚è¢«é”™è¯¯é‡åŒ–")
            
            print("\nğŸ’¡ å»ºè®®è§£å†³æ–¹æ¡ˆ:")
            print("  1. å°è¯•é™æ€é‡åŒ–è€Œä¸æ˜¯åŠ¨æ€é‡åŒ–")
            print("  2. è°ƒæ•´é‡åŒ–å‚æ•°ï¼Œå‡å°‘é‡åŒ–æ“ä½œ")
            print("  3. ä½¿ç”¨æ›´ä¸“ä¸šçš„é‡åŒ–å·¥å…·")
            print("  4. è€ƒè™‘åªé‡åŒ–æƒé‡ï¼Œä¿æŒæ¿€æ´»å€¼ä¸º FP32")
        else:
            print("\nâœ… é‡åŒ–æ¨¡å‹æ€§èƒ½æå‡!")

if __name__ == "__main__":
    compare_models()
